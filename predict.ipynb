{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2j9xris9xVaU","outputId":"bdd1b0ea-9be3-40e8-dec5-a998cb012200","executionInfo":{"status":"ok","timestamp":1708280203478,"user_tz":-330,"elapsed":31707,"user":{"displayName":"Mansi Mishra","userId":"04256905725587643817"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/AWS_AI_ML_Scholar\n"]}],"source":["# prompt: mount drive for specific folder in drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd \"/content/drive/MyDrive/AWS_AI_ML_Scholar\"\n"]},{"cell_type":"code","source":["import argparse                                #DEVELOPER : Abdul Basit\n","import torch\n","from torch.autograd import Variable\n","from torchvision import transforms, models\n","import torch.nn.functional as F\n","import numpy as np\n","from PIL import Image\n","import json\n","import os\n","import random\n","import warnings\n","import PIL\n","import math\n","\n","\n","def parse_args():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--save_dir', dest=\"save_dir\", action=\"store\", default=\"./checkpoint.pth\")\n","    parser.add_argument('--top_k', dest='top_k', default=3)\n","    parser.add_argument('--filepath', dest='filepath', default='flower_data/test/16/image_06657.jpg') # use a deafault filepath to a primrose image\n","    parser.add_argument('--category_names', dest='category_names', default='cat_to_name_.json')\n","    parser.add_argument('--gpu', action='store', default='gpu')\n","    args = parser.parse_args(args=[])\n","    return args\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# def predict(image_path, model,device, topk=5):\n","    # ''' Predict the class (or classes) of an image using a trained deep learning model.\n","    # '''\n","\n","    # model.to(device)\n","    # model.eval();\n","    # # Convert image from numpy to torch\n","    # torch_image = torch.from_numpy(np.expand_dims(process_image(image_path), axis=0)).type(torch.FloatTensor).to(device)\n","\n","    # # Find probabilities (results) by passing through the function (note the log softmax means that its on a log scale)\n","    # log_probs = model.forward(torch_image)\n","\n","    # # Convert to linear scale\n","    # linear_probs = torch.exp(log_probs)\n","\n","    # # Find the top 3 results\n","    # top_probs, top_labels = linear_probs.topk(topk)\n","    # top_probs = np.array(top_probs.detach().cpu())[0]  # Move to CPU before converting to NumPy\n","    # top_labels = np.array(top_labels.detach().cpu())[0]\n","    # with open('cat_to_name.json', 'r') as f:\n","    #     cat_to_name = json.load(f)\n","\n","    # # Convert to classes\n","    # idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n","    # top_labels = [idx_to_class[lab] for lab in top_labels]\n","    # top_flowers = [cat_to_name[lab] for lab in top_labels]\n","\n","    # return top_probs, top_labels, top_flowers\n","\n","def predict_custom(image_path, model, device, topk=5):\n","    ''' Predict the class (or classes) of an image using a trained deep learning model.\n","    This is a customized version of the predict function with a different structure.\n","    '''\n","\n","    # Move the model to the specified device\n","    model.to(device)\n","    model.eval()\n","\n","    # Preprocess the image and convert it to a PyTorch tensor\n","    processed_image = torch.from_numpy(np.expand_dims(process_image(image_path), axis=0)).type(torch.FloatTensor).to(device)\n","\n","    # Forward pass to get the log probabilities\n","    log_probs = model(processed_image)\n","\n","    # Convert log probabilities to linear scale\n","    linear_probs = torch.exp(log_probs)\n","\n","    # Get the top probabilities and corresponding labels\n","    top_probability, top_labels = linear_probs.topk(topk)\n","    top_probability = np.array(top_probability.detach().cpu())[0]\n","    top_labels = np.array(top_labels.detach().cpu())[0]\n","\n","    # Load the mapping from category index to category name\n","    with open('cat_to_name.json', 'r') as f:\n","        cat_to_name = json.load(f)\n","\n","    # Map indices to class labels\n","    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n","    top_labels = [idx_to_class[lab] for lab in top_labels]\n","\n","    # Map class labels to flower names\n","    top_flowers = [cat_to_name[lab] for lab in top_labels]\n","\n","    return top_probability, top_labels, top_flowers\n","\n","\n","\n","# Scales, crops, and normalizes a PIL image for a PyTorch model,returns an Numpy array\n","def process_image(image):\n","    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n","        returns an Numpy array\n","    '''\n","\n","    # TODO: Process a PIL image for use in a PyTorch model\n","        #size = 256, 256\n","    #loading image\n","    im = PIL.Image.open(image)\n","    #original size\n","    width, height = im.size\n","\n","    if width > height:\n","        height = 256\n","\n","    else:\n","        width = 256\n","    im.thumbnail ((width,50000), Image.ANTIALIAS)\n","    #new size of im\n","    width, height = im.size\n","    #crop 224x224 in the center\n","    reduce = 224\n","    left = (width - reduce)/2\n","    top = (height - reduce)/2\n","    right = left + 224\n","    bottom = top + 224\n","    im = im.crop ((left, top, right, bottom))\n","\n","    #preparing numpy array\n","    #to make values from 0 to 1\n","    numpy_img = np.array(im)/255\n","    # Normalize each color channel\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    numpy_img = (numpy_img-mean)/std\n","\n","    numpy_img= numpy_img.transpose ((2,0,1))\n","    return numpy_img\n","\n","\n","\n","def print_probability(probs, flowers):\n","    #Converts two lists into a dictionary to print on screen\n","    for i, j in enumerate(zip(flowers, probs)):\n","        print (\"Rank {}:\".format(i+1),\n","               \"Flower: {}, liklihood: {}%\".format(j[1], math.ceil(j[0]*100)))\n","\n","\n","# Loading the trained model\n","def load_checkpoint(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    model = models.vgg19(pretrained=True)\n","    model.name = \"vgg19\"\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    # Load from checkpoint\n","    model.classifier = checkpoint['classifier']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    model.class_to_idx = checkpoint['mapping']\n","    return model\n","\n","\n","def main():\n","  args = parse_args()\n","  args.category_names = \"cat_to_name.json\"\n","  with open(args.category_names, 'r') as f:\n","        cat_to_name = json.load(f)\n","  #load the trained models\n","  model = load_checkpoint(args.save_dir)\n","  image_tensor = process_image(args.filepath)\n","  image_tensor = torch.from_numpy(image_tensor)\n","  image_tensor = image_tensor.to(device)\n","  #checkng for available device\n","\n","  #getting the predictions\n","  top_probability, top_labels, top_flowers = predict_custom(args.filepath,model,device,args.top_k)\n","  print(top_probability)\n","  print_probability(top_flowers, top_probability)\n","  warnings.filterwarnings('ignore')\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"V3UOQmrcyOlW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"77108273-ea94-4910-bf6b-2f4933a1fae2","executionInfo":{"status":"ok","timestamp":1708280239093,"user_tz":-330,"elapsed":35625,"user":{"displayName":"Mansi Mishra","userId":"04256905725587643817"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|██████████| 548M/548M [00:06<00:00, 88.5MB/s]\n","<ipython-input-2-638cd4b51c76>:114: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im.thumbnail ((width,50000), Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["[0.2986687  0.1407441  0.09940755]\n","Rank 1: Flower: watercress, liklihood: 30%\n","Rank 2: Flower: canna lily, liklihood: 15%\n","Rank 3: Flower: corn poppy, liklihood: 10%\n"]}]},{"cell_type":"code","source":["import argparse  # DEVELOPER: Abdul Basit\n","import json\n","import math\n","import numpy as np\n","import os\n","from PIL import Image\n","import random\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","from torchvision import transforms, models\n","import warnings\n","\n","\n","def main():\n","    # Parse command line arguments\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--save_dir', dest=\"save_dir\", action=\"store\", default=\"./checkpoint.pth\")\n","    parser.add_argument('--top_k', dest='top_k', default=3)\n","    parser.add_argument('--filepath', dest='filepath', default='flower_data/test/16/image_06657.jpg')  # use a default filepath to a primrose image\n","    parser.add_argument('--category_names', dest='category_names', default='cat_to_name_.json')\n","    parser.add_argument('--gpu', action='store', default='gpu')\n","    args = parser.parse_args(args=[])\n","\n","    args.category_names = \"cat_to_name.json\"\n","    with open(args.category_names, 'r') as f:\n","        cat_to_name = json.load(f)\n","\n","    # Load the trained model\n","    device = check_gpu(gpu_arg=args.gpu)\n","    model = load_checkpoint(args.save_dir)\n","\n","    # Preprocess the image\n","    image_tensor = process_image(args.filepath)\n","    image_tensor = torch.from_numpy(image_tensor)\n","    image_tensor = image_tensor.to(device)\n","\n","    # Get predictions\n","    top_probs, top_labels, top_flowers = predict(args.filepath, model, device, args.top_k)\n","    print(\"Top probabilities:\", top_probs)\n","    print(\"Top labels and flowers:\")\n","    print_probability(top_flowers, top_probs)\n","    warnings.filterwarnings('ignore')\n","\n","\n","def gpu_check(arg_gpu):\n","    \"\"\"\n","    Check for GPU availability and set the device accordingly.\n","    \"\"\"\n","    if not arg_gpu or arg_gpu == \"cpu\":\n","        return torch.device(\"cpu\")\n","    gpu_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    return gpu_device\n","\n","\n","def preprocess_image(image_path):\n","    '''\n","    Preprocesses a PIL image for a PyTorch model,\n","    returns a NumPy array\n","    '''\n","    # Load image\n","    image = Image.open(image_path)\n","\n","    # Resize image while maintaining aspect ratio\n","    width, height = image.size\n","    if width > height:\n","        height = 256\n","    else:\n","        width = 256\n","    image.thumbnail((width, 50000), Image.ANTIALIAS)\n","\n","    # Crop center to 224x224\n","    reduce = 224\n","    left = (width - reduce) / 2\n","    top = (height - reduce) / 2\n","    right = left + 224\n","    bottom = top + 224\n","    image = image.crop((left, top, right, bottom))\n","\n","    # Convert image to numpy array and normalize\n","    numpy_img = np.array(image) / 255\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    numpy_img = (numpy_img - mean) / std\n","\n","    # Transpose dimensions\n","    numpy_img = numpy_img.transpose((2, 0, 1))\n","\n","    # Print processed image dimensions\n","    print(\"Processed image dimensions:\", numpy_img.shape)\n","\n","    return numpy_img\n","\n","\n","def make_prediction(image_path, model, device, topk=5):\n","    ''' Make a prediction for an image using a trained deep learning model.\n","    '''\n","    model.to(device)\n","    model.eval()\n","    print('Using device:', device)\n","\n","    # Convert image from numpy to torch\n","    torch_image = torch.from_numpy(np.expand_dims(preprocess_image(image_path), axis=0)).type(torch.FloatTensor).to(device)\n","\n","    # Find probabilities (results) by passing through the model\n","    log_probs = model.forward(torch_image)\n","\n","    # Convert to linear scale\n","    linear_probs = torch.exp(log_probs)\n","\n","    # Find the top results\n","    top_probs, top_labels = linear_probs.topk(topk)\n","    top_probs = np.array(top_probs.detach().cpu())[0]  # Move to CPU before converting to NumPy\n","    top_labels = np.array(top_labels.detach().cpu())[0]\n","\n","    # Load class names\n","    with open('cat_to_name.json', 'r') as f:\n","        cat_to_name = json.load(f)\n","\n","    # Convert labels to class names\n","    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n","    top_labels = [idx_to_class[lab] for lab in top_labels]\n","    top_flowers = [cat_to_name[lab] for lab in top_labels]\n","\n","    return top_probs, top_labels, top_flowers\n","\n","\n","def display_probabilities(probs, flowers):\n","    # Convert two lists into a dictionary to print on screen\n","    for i, j in enumerate(zip(flowers, probs)):\n","        print(\"Rank {}:\".format(i + 1),\n","              \"Flower: {}, likelihood: {}%\".format(j[1], math.ceil(j[0] * 100)))\n","\n","def load_checkpoint(checkpoint_path):\n","    # Load the model checkpoint and return the model\n","    checkpoint = torch.load(checkpoint_path)\n","    model = models.vgg19(pretrained=True)\n","    model.name = \"vgg19\"\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    # Load from the checkpoint\n","    model.classifier = checkpoint['classifier']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    model.class_to_idx = checkpoint['mapping']\n","    return model\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uz1BLXWvdZIe","executionInfo":{"status":"ok","timestamp":1708281038703,"user_tz":-330,"elapsed":2234,"user":{"displayName":"Mansi Mishra","userId":"04256905725587643817"}},"outputId":"95cb9106-aa2b-496e-8827-2894ec99b951"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Device  cuda:0\n","Top probabilities: [0.2986687  0.1407441  0.09940755]\n","Top labels and flowers:\n","Rank 1: Flower: watercress, liklihood: 30%\n","Rank 2: Flower: canna lily, liklihood: 15%\n","Rank 3: Flower: corn poppy, liklihood: 10%\n"]}]}]}