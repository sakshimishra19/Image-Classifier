{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j9xris9xVaU",
        "outputId": "bdd1b0ea-9be3-40e8-dec5-a998cb012200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/AWS_AI_ML_Scholar\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive for specific folder in drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd \"/content/drive/MyDrive/AWS_AI_ML_Scholar\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse  # DEVELOPER: Abdul Basit\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "import warnings\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Parse command line arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--save_dir', dest=\"save_dir\", action=\"store\", default=\"./checkpoint.pth\")\n",
        "    parser.add_argument('--top_k', dest='top_k', default=3)\n",
        "    parser.add_argument('--filepath', dest='filepath', default='flower_data/test/16/image_06657.jpg')  # use a default filepath to a primrose image\n",
        "    parser.add_argument('--category_names', dest='category_names', default='cat_to_name_.json')\n",
        "    parser.add_argument('--gpu', action='store', default='gpu')\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    args.category_names = \"cat_to_name.json\"\n",
        "    with open(args.category_names, 'r') as f:\n",
        "        cat_to_name = json.load(f)\n",
        "\n",
        "    # Load the trained model\n",
        "    device = check_gpu(gpu_arg=args.gpu)\n",
        "    model = load_checkpoint(args.save_dir)\n",
        "\n",
        "    # Preprocess the image\n",
        "    image_tensor = process_image(args.filepath)\n",
        "    image_tensor = torch.from_numpy(image_tensor)\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    top_probs, top_labels, top_flowers = predict(args.filepath, model, device, args.top_k)\n",
        "    print(\"Top probabilities:\", top_probs)\n",
        "    print(\"Top labels and flowers:\")\n",
        "    print_probability(top_flowers, top_probs)\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def gpu_check(arg_gpu):\n",
        "    \"\"\"\n",
        "    Check for GPU availability and set the device accordingly.\n",
        "    \"\"\"\n",
        "    if not arg_gpu or arg_gpu == \"cpu\":\n",
        "        return torch.device(\"cpu\")\n",
        "    gpu_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return gpu_device\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    '''\n",
        "    Preprocesses a PIL image for a PyTorch model,\n",
        "    returns a NumPy array\n",
        "    '''\n",
        "    # Load image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Resize image while maintaining aspect ratio\n",
        "    width, height = image.size\n",
        "    if width > height:\n",
        "        height = 256\n",
        "    else:\n",
        "        width = 256\n",
        "    image.thumbnail((width, 50000), Image.ANTIALIAS)\n",
        "\n",
        "    # Crop center to 224x224\n",
        "    reduce = 224\n",
        "    left = (width - reduce) / 2\n",
        "    top = (height - reduce) / 2\n",
        "    right = left + 224\n",
        "    bottom = top + 224\n",
        "    image = image.crop((left, top, right, bottom))\n",
        "\n",
        "    # Convert image to numpy array and normalize\n",
        "    numpy_img = np.array(image) / 255\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    numpy_img = (numpy_img - mean) / std\n",
        "\n",
        "    # Transpose dimensions\n",
        "    numpy_img = numpy_img.transpose((2, 0, 1))\n",
        "\n",
        "    # Print processed image dimensions\n",
        "    print(\"Processed image dimensions:\", numpy_img.shape)\n",
        "\n",
        "    return numpy_img\n",
        "\n",
        "\n",
        "def make_prediction(image_path, model, device, topk=5):\n",
        "    ''' Make a prediction for an image using a trained deep learning model.\n",
        "    '''\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print('Using device:', device)\n",
        "\n",
        "    # Convert image from numpy to torch\n",
        "    torch_image = torch.from_numpy(np.expand_dims(preprocess_image(image_path), axis=0)).type(torch.FloatTensor).to(device)\n",
        "\n",
        "    # Find probabilities (results) by passing through the model\n",
        "    log_probs = model.forward(torch_image)\n",
        "\n",
        "    # Convert to linear scale\n",
        "    linear_probs = torch.exp(log_probs)\n",
        "\n",
        "    # Find the top results\n",
        "    top_probs, top_labels = linear_probs.topk(topk)\n",
        "    top_probs = np.array(top_probs.detach().cpu())[0]  # Move to CPU before converting to NumPy\n",
        "    top_labels = np.array(top_labels.detach().cpu())[0]\n",
        "\n",
        "    # Load class names\n",
        "    with open('cat_to_name.json', 'r') as f:\n",
        "        cat_to_name = json.load(f)\n",
        "\n",
        "    # Convert labels to class names\n",
        "    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n",
        "    top_labels = [idx_to_class[lab] for lab in top_labels]\n",
        "    top_flowers = [cat_to_name[lab] for lab in top_labels]\n",
        "\n",
        "    return top_probs, top_labels, top_flowers\n",
        "\n",
        "\n",
        "def display_probabilities(probs, flowers):\n",
        "    # Convert two lists into a dictionary to print on screen\n",
        "    for i, j in enumerate(zip(flowers, probs)):\n",
        "        print(\"Rank {}:\".format(i + 1),\n",
        "              \"Flower: {}, likelihood: {}%\".format(j[1], math.ceil(j[0] * 100)))\n",
        "\n",
        "def load_checkpoint(checkpoint_path):\n",
        "    # Load the model checkpoint and return the model\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    model.name = \"vgg19\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Load from the checkpoint\n",
        "    model.classifier = checkpoint['classifier']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.class_to_idx = checkpoint['mapping']\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6-KOTjtgqXO",
        "outputId": "1b87c602-db78-4cdc-c5fa-af1b0dbc0727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device  cuda:0\n",
            "Top probabilities: [0.2986687  0.1407441  0.09940755]\n",
            "Top labels and flowers:\n",
            "Rank 1: Flower: watercress, liklihood: 30%\n",
            "Rank 2: Flower: canna lily, liklihood: 15%\n",
            "Rank 3: Flower: corn poppy, liklihood: 10%\n"
          ]
        }
      ]
    }
  ]
}